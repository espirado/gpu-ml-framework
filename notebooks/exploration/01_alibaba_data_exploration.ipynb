{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alibaba GPU Cluster Data Exploration\n",
    "\n",
    "## Research Objective\n",
    "Behavioral pattern recognition for autonomous ML infrastructure optimization\n",
    "\n",
    "## Primary Dataset: cluster-trace-gpu-v2020\n",
    "- **Scale**: 6,500+ GPUs across 1,800 machines\n",
    "- **Duration**: 2 months (July-August 2020)\n",
    "- **Users**: 1,300+ users\n",
    "- **Workloads**: Training and inference jobs\n",
    "\n",
    "## Key Research Questions\n",
    "1. What behavioral patterns exist in GPU resource usage?\n",
    "2. Can we identify resource hoarding patterns?\n",
    "3. What temporal patterns exist in job submissions?\n",
    "4. How do recurring tasks behave differently?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Observability Research - Alibaba Data Exploration\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print('GPU Observability Research - Alibaba Data Exploration')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Status:\n",
      "------------------------------\n",
      "GPU 2020: ✗ Not found\n",
      "GPU 2023: ✗ Not found\n",
      "\n",
      "To get full datasets:\n",
      "1. See: ../data/raw/ACCESS_GUIDE.md\n",
      "2. Complete surveys for dataset access\n",
      "3. Download and extract data files\n"
     ]
    }
   ],
   "source": [
    "# Check dataset availability\n",
    "data_path = Path('../data/raw')\n",
    "\n",
    "datasets = {\n",
    "    'GPU 2020': data_path / 'cluster-trace-gpu-v2020',\n",
    "    'GPU 2023': data_path / 'cluster-trace-gpu-v2023'\n",
    "}\n",
    "\n",
    "print('Dataset Status:')\n",
    "print('-' * 30)\n",
    "\n",
    "for name, path in datasets.items():\n",
    "    if path.exists():\n",
    "        files = list(path.glob('*.csv'))\n",
    "        status = f'✓ Found ({len(files)} CSV files)' if files else '⚠ Metadata only'\n",
    "        print(f'{name}: {status}')\n",
    "        \n",
    "        # Show info if available\n",
    "        info_file = path / 'dataset_info.json'\n",
    "        if info_file.exists():\n",
    "            with open(info_file) as f:\n",
    "                info = json.load(f)\n",
    "            print(f'  Description: {info.get(\"description\", \"N/A\")}')\n",
    "    else:\n",
    "        print(f'{name}: ✗ Not found')\n",
    "\n",
    "print('\\nTo get full datasets:')\n",
    "print('1. See: ../data/raw/ACCESS_GUIDE.md')\n",
    "print('2. Complete surveys for dataset access')\n",
    "print('3. Download and extract data files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (Run after downloading full datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPU 2020 dataset (primary focus)\n",
    "gpu_2020_path = data_path / 'cluster-trace-gpu-v2020'\n",
    "\n",
    "if (gpu_2020_path / 'job_table.csv').exists():\n",
    "    print('Loading GPU 2020 dataset...')\n",
    "    \n",
    "    # Core tables for behavioral analysis\n",
    "    jobs_df = pd.read_csv(gpu_2020_path / 'job_table.csv')\n",
    "    tasks_df = pd.read_csv(gpu_2020_path / 'task_table.csv')\n",
    "    instances_df = pd.read_csv(gpu_2020_path / 'instance_table.csv')\n",
    "    machines_df = pd.read_csv(gpu_2020_path / 'machine_attributes.csv')\n",
    "    \n",
    "    print(f'Jobs: {jobs_df.shape}')\n",
    "    print(f'Tasks: {tasks_df.shape}')\n",
    "    print(f'Instances: {instances_df.shape}')\n",
    "    print(f'Machines: {machines_df.shape}')\n",
    "    \n",
    "    # Show basic info\n",
    "    print('\\nJob table columns:')\n",
    "    print(jobs_df.columns.tolist())\n",
    "    \n",
    "else:\n",
    "    print('⚠ Full dataset not available')\n",
    "    print('Complete survey to download: cluster-trace-gpu-v2020')\n",
    "    print('See: ../data/raw/ACCESS_GUIDE.md')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
